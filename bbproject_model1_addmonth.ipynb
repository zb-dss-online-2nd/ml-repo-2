{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grade 1~4 기준\n",
    "- 항목: month, obp, slg, ba, era, whip + grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구단별 No\n",
    "\n",
    "# 1. kt wiz\n",
    "# 2. 두산 베어스\n",
    "# 3. 삼성 라이온즈\n",
    "# 4. LG 트윈스\n",
    "# 5. 키움히어로즈\n",
    "# 6. SSG 랜더스\n",
    "# 7. NC 다이노스\n",
    "# 8. 롯데 자이언츠\n",
    "# 9. 기아 타이거즈\n",
    "# 10. 한화 이글스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pov</th>\n",
       "      <th>obp</th>\n",
       "      <th>slg</th>\n",
       "      <th>ba</th>\n",
       "      <th>era</th>\n",
       "      <th>whip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.284</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.208</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.263</td>\n",
       "      <td>5.72</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.290</td>\n",
       "      <td>5.93</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.274</td>\n",
       "      <td>5.73</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.231</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.263</td>\n",
       "      <td>4.92</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.219</td>\n",
       "      <td>4.18</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.225</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.251</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team  year  month    pov    obp    slg     ba   era  whip\n",
       "0       1  2015      3  0.000  0.403  0.412  0.284  8.28  1.92\n",
       "1       1  2015      4  0.136  0.290  0.295  0.208  5.52  1.79\n",
       "2       1  2015      5  0.259  0.342  0.356  0.263  5.72  1.58\n",
       "3       1  2015      6  0.478  0.353  0.456  0.290  5.93  1.68\n",
       "4       1  2015      7  0.444  0.339  0.431  0.274  5.73  1.60\n",
       "..    ...   ...    ...    ...    ...    ...    ...   ...   ...\n",
       "529    10  2021      8  0.500  0.331  0.331  0.231  4.33  1.46\n",
       "530    10  2021      9  0.381  0.361  0.373  0.263  4.92  1.38\n",
       "531    10  2021     10  0.278  0.318  0.310  0.219  4.18  1.47\n",
       "532    10  2022      4  0.360  0.309  0.309  0.225  4.00  1.40\n",
       "533    10  2022      5  0.385  0.318  0.387  0.251  6.51  1.67\n",
       "\n",
       "[534 rows x 9 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = pd.read_csv(\"./Raw_First_Value.csv\") \n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 534 entries, 0 to 533\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   team    534 non-null    int64  \n",
      " 1   year    534 non-null    int64  \n",
      " 2   month   534 non-null    int64  \n",
      " 3   pov     534 non-null    float64\n",
      " 4   obp     534 non-null    float64\n",
      " 5   slg     534 non-null    float64\n",
      " 6   ba      534 non-null    float64\n",
      " 7   era     534 non-null    float64\n",
      " 8   whip    534 non-null    float64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 37.7 KB\n"
     ]
    }
   ],
   "source": [
    "bb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 승률별 등급 차등 분류\n",
    "\n",
    "def get_grade_1(pov):\n",
    "    if pov>=0.60:\n",
    "        grade = 4\n",
    "    elif pov>=0.50:\n",
    "        grade = 3\n",
    "    elif pov>=0.40:\n",
    "        grade = 2\n",
    "    else:\n",
    "        grade = 1\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grade 1~4 기준 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pov</th>\n",
       "      <th>obp</th>\n",
       "      <th>slg</th>\n",
       "      <th>ba</th>\n",
       "      <th>era</th>\n",
       "      <th>whip</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.284</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.208</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.263</td>\n",
       "      <td>5.72</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.290</td>\n",
       "      <td>5.93</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.274</td>\n",
       "      <td>5.73</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.231</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.263</td>\n",
       "      <td>4.92</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.219</td>\n",
       "      <td>4.18</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.225</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.251</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team  year  month    pov    obp    slg     ba   era  whip  grade\n",
       "0       1  2015      3  0.000  0.403  0.412  0.284  8.28  1.92      1\n",
       "1       1  2015      4  0.136  0.290  0.295  0.208  5.52  1.79      1\n",
       "2       1  2015      5  0.259  0.342  0.356  0.263  5.72  1.58      1\n",
       "3       1  2015      6  0.478  0.353  0.456  0.290  5.93  1.68      2\n",
       "4       1  2015      7  0.444  0.339  0.431  0.274  5.73  1.60      2\n",
       "..    ...   ...    ...    ...    ...    ...    ...   ...   ...    ...\n",
       "529    10  2021      8  0.500  0.331  0.331  0.231  4.33  1.46      3\n",
       "530    10  2021      9  0.381  0.361  0.373  0.263  4.92  1.38      1\n",
       "531    10  2021     10  0.278  0.318  0.310  0.219  4.18  1.47      1\n",
       "532    10  2022      4  0.360  0.309  0.309  0.225  4.00  1.40      1\n",
       "533    10  2022      5  0.385  0.318  0.387  0.251  6.51  1.67      1\n",
       "\n",
       "[534 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grade 1~4 기준 (Grade 4 = 0.60 이상 , Grade 3 = 0.50 이상 0.60 미만, Grade 2 = 0.40 이상 0.50 미만, Grade 1 = 0.40 미만)\n",
    "bb['grade'] = bb['pov'].apply(lambda pov: get_grade_1(pov))\n",
    "bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS 1. 상수 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>grade</td>      <th>  R-squared (uncentered):</th>      <td>   0.927</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.926</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1115.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 15 Jun 2022</td> <th>  Prob (F-statistic):</th>          <td>4.81e-296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:31:42</td>     <th>  Log-Likelihood:    </th>          <td> -606.32</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   534</td>      <th>  AIC:               </th>          <td>   1225.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   528</td>      <th>  BIC:               </th>          <td>   1250.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month</th> <td>    0.0006</td> <td>    0.015</td> <td>    0.039</td> <td> 0.969</td> <td>   -0.030</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>obp</th>   <td>    9.7901</td> <td>    1.896</td> <td>    5.163</td> <td> 0.000</td> <td>    6.065</td> <td>   13.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slg</th>   <td>    7.5112</td> <td>    0.969</td> <td>    7.750</td> <td> 0.000</td> <td>    5.607</td> <td>    9.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ba</th>    <td>   -3.9094</td> <td>    2.591</td> <td>   -1.509</td> <td> 0.132</td> <td>   -8.998</td> <td>    1.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>era</th>   <td>   -0.5744</td> <td>    0.046</td> <td>  -12.408</td> <td> 0.000</td> <td>   -0.665</td> <td>   -0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>whip</th>  <td>   -0.1242</td> <td>    0.245</td> <td>   -0.506</td> <td> 0.613</td> <td>   -0.606</td> <td>    0.358</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.748</td> <th>  Durbin-Watson:     </th> <td>   1.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.034</td> <th>  Jarque-Bera (JB):  </th> <td>   7.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.208</td> <th>  Prob(JB):          </th> <td>  0.0300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.377</td> <th>  Cond. No.          </th> <td>    787.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  grade   R-squared (uncentered):                   0.927\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.926\n",
       "Method:                 Least Squares   F-statistic:                              1115.\n",
       "Date:                Wed, 15 Jun 2022   Prob (F-statistic):                   4.81e-296\n",
       "Time:                        23:31:42   Log-Likelihood:                         -606.32\n",
       "No. Observations:                 534   AIC:                                      1225.\n",
       "Df Residuals:                     528   BIC:                                      1250.\n",
       "Df Model:                           6                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "month          0.0006      0.015      0.039      0.969      -0.030       0.031\n",
       "obp            9.7901      1.896      5.163      0.000       6.065      13.515\n",
       "slg            7.5112      0.969      7.750      0.000       5.607       9.415\n",
       "ba            -3.9094      2.591     -1.509      0.132      -8.998       1.180\n",
       "era           -0.5744      0.046    -12.408      0.000      -0.665      -0.483\n",
       "whip          -0.1242      0.245     -0.506      0.613      -0.606       0.358\n",
       "==============================================================================\n",
       "Omnibus:                        6.748   Durbin-Watson:                   1.933\n",
       "Prob(Omnibus):                  0.034   Jarque-Bera (JB):                7.015\n",
       "Skew:                          -0.208   Prob(JB):                       0.0300\n",
       "Kurtosis:                       3.377   Cond. No.                         787.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=grade\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = bb[['month', 'obp', 'slg', 'ba', 'era', 'whip']]\n",
    "y = bb['grade']\n",
    "lm = sm.OLS(y, X).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>pov</td>       <th>  R-squared (uncentered):</th>      <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1582.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 15 Jun 2022</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:31:43</td>     <th>  Log-Likelihood:    </th>          <td>  368.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   534</td>      <th>  AIC:               </th>          <td>  -724.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   528</td>      <th>  BIC:               </th>          <td>  -698.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month</th> <td>    0.0027</td> <td>    0.002</td> <td>    1.094</td> <td> 0.274</td> <td>   -0.002</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>obp</th>   <td>    2.3747</td> <td>    0.306</td> <td>    7.767</td> <td> 0.000</td> <td>    1.774</td> <td>    2.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slg</th>   <td>    1.2894</td> <td>    0.156</td> <td>    8.252</td> <td> 0.000</td> <td>    0.982</td> <td>    1.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ba</th>    <td>   -1.6190</td> <td>    0.418</td> <td>   -3.877</td> <td> 0.000</td> <td>   -2.439</td> <td>   -0.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>era</th>   <td>   -0.0908</td> <td>    0.007</td> <td>  -12.162</td> <td> 0.000</td> <td>   -0.105</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>whip</th>  <td>   -0.0052</td> <td>    0.040</td> <td>   -0.132</td> <td> 0.895</td> <td>   -0.083</td> <td>    0.072</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>92.687</td> <th>  Durbin-Watson:     </th> <td>   1.934</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 981.822</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.363</td> <th>  Prob(JB):          </th> <td>6.31e-214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.603</td> <th>  Cond. No.          </th> <td>    787.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                    pov   R-squared (uncentered):                   0.947\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.947\n",
       "Method:                 Least Squares   F-statistic:                              1582.\n",
       "Date:                Wed, 15 Jun 2022   Prob (F-statistic):                        0.00\n",
       "Time:                        23:31:43   Log-Likelihood:                          368.24\n",
       "No. Observations:                 534   AIC:                                     -724.5\n",
       "Df Residuals:                     528   BIC:                                     -698.8\n",
       "Df Model:                           6                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "month          0.0027      0.002      1.094      0.274      -0.002       0.008\n",
       "obp            2.3747      0.306      7.767      0.000       1.774       2.975\n",
       "slg            1.2894      0.156      8.252      0.000       0.982       1.596\n",
       "ba            -1.6190      0.418     -3.877      0.000      -2.439      -0.799\n",
       "era           -0.0908      0.007    -12.162      0.000      -0.105      -0.076\n",
       "whip          -0.0052      0.040     -0.132      0.895      -0.083       0.072\n",
       "==============================================================================\n",
       "Omnibus:                       92.687   Durbin-Watson:                   1.934\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              981.822\n",
       "Skew:                          -0.363   Prob(JB):                    6.31e-214\n",
       "Kurtosis:                       9.603   Cond. No.                         787.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=pov\n",
    "\n",
    "X = bb[['month','obp', 'slg', 'ba', 'era', 'whip']]\n",
    "y = bb['pov']\n",
    "lm = sm.OLS(y, X).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS 2. 상수 O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  grade   R-squared:                       0.511\n",
      "Model:                            OLS   Adj. R-squared:                  0.506\n",
      "Method:                 Least Squares   F-statistic:                     91.92\n",
      "Date:                Wed, 15 Jun 2022   Prob (F-statistic):           1.03e-78\n",
      "Time:                        23:31:44   Log-Likelihood:                -605.98\n",
      "No. Observations:                 534   AIC:                             1226.\n",
      "Df Residuals:                     527   BIC:                             1256.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4134      0.500      0.827      0.408      -0.568       1.395\n",
      "month         -0.0010      0.016     -0.064      0.949      -0.031       0.029\n",
      "obp            8.7736      2.260      3.882      0.000       4.334      13.213\n",
      "slg            7.5952      0.975      7.792      0.000       5.680       9.510\n",
      "ba            -3.7232      2.601     -1.431      0.153      -8.833       1.387\n",
      "era           -0.5606      0.049    -11.390      0.000      -0.657      -0.464\n",
      "whip          -0.2593      0.295     -0.880      0.380      -0.839       0.320\n",
      "==============================================================================\n",
      "Omnibus:                        6.928   Durbin-Watson:                   1.921\n",
      "Prob(Omnibus):                  0.031   Jarque-Bera (JB):                7.251\n",
      "Skew:                          -0.209   Prob(JB):                       0.0266\n",
      "Kurtosis:                       3.388   Cond. No.                         826.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# y=grade\n",
    "\n",
    "feature_names= ['month','obp', 'slg', 'ba', 'era','whip']\n",
    "\n",
    "#X변수 설정\n",
    "dfX0 = pd.DataFrame(bb, columns=feature_names)\n",
    "#y변수 설정\n",
    "dfy = pd.DataFrame(bb, columns=[\"grade\"] )\n",
    "#상수항 설정\n",
    "dfX = sm.add_constant(dfX0)\n",
    "\n",
    "\n",
    "model_baseball = sm.OLS(dfy, dfX)\n",
    "result_baseball_ols = model_baseball.fit()\n",
    "print(result_baseball_ols.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    pov   R-squared:                       0.506\n",
      "Model:                            OLS   Adj. R-squared:                  0.501\n",
      "Method:                 Least Squares   F-statistic:                     90.05\n",
      "Date:                Wed, 15 Jun 2022   Prob (F-statistic):           1.59e-77\n",
      "Time:                        23:31:45   Log-Likelihood:                 370.39\n",
      "No. Observations:                 534   AIC:                            -726.8\n",
      "Df Residuals:                     527   BIC:                            -696.8\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1658      0.080      2.065      0.039       0.008       0.323\n",
      "month          0.0021      0.002      0.831      0.406      -0.003       0.007\n",
      "obp            1.9670      0.363      5.417      0.000       1.254       2.680\n",
      "slg            1.3230      0.157      8.448      0.000       1.015       1.631\n",
      "ba            -1.5444      0.418     -3.695      0.000      -2.365      -0.723\n",
      "era           -0.0852      0.008    -10.777      0.000      -0.101      -0.070\n",
      "whip          -0.0594      0.047     -1.255      0.210      -0.153       0.034\n",
      "==============================================================================\n",
      "Omnibus:                       97.269   Durbin-Watson:                   1.915\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              984.011\n",
      "Skew:                          -0.436   Prob(JB):                    2.11e-214\n",
      "Kurtosis:                       9.593   Cond. No.                         826.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# y=pov\n",
    "\n",
    "feature_names= ['month','obp', 'slg', 'ba', 'era','whip']\n",
    "\n",
    "#X변수 설정\n",
    "dfX0 = pd.DataFrame(bb, columns=feature_names)\n",
    "#y변수 설정\n",
    "dfy = pd.DataFrame(bb, columns=[\"pov\"] )\n",
    "#상수항 설정\n",
    "dfX = sm.add_constant(dfX0)\n",
    "\n",
    "\n",
    "model_baseball = sm.OLS(dfy, dfX)\n",
    "result_baseball_ols = model_baseball.fit()\n",
    "print(result_baseball_ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS 3. 비교\n",
    "* 상수 없음\n",
    "  - grade : R-Squared : 0.927 / AIC : 1225.\n",
    "  - pov : R-Squared : 0.947 /AIC : -724.5\n",
    "* 상수 있음\n",
    "  - grade : R-Squared : 0.511 / AIC : 1226.\n",
    "  - pov : R-Squared : 0.506 /AIC : -726.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Size 1. 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc :  0.7822014051522248\n",
      "Test Acc :  0.5327102803738317\n"
     ]
    }
   ],
   "source": [
    "X=bb[['month','obp', 'slg', 'ba', 'era','whip']]\n",
    "y=bb['grade']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=13, stratify=y)\n",
    "\n",
    "cc = DecisionTreeClassifier(max_depth=7, random_state=13)\n",
    "cc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tr = cc.predict(X_train)\n",
    "y_pred_test = cc.predict(X_test)\n",
    "\n",
    "\n",
    "print('Train Acc : ', accuracy_score(y_train, y_pred_tr))\n",
    "print('Test Acc : ', accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Size 2. 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc :  0.8123324396782842\n",
      "Test Acc :  0.5403726708074534\n"
     ]
    }
   ],
   "source": [
    "X=bb[['month','obp', 'slg', 'ba', 'era','whip']]\n",
    "y=bb['grade']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=13, stratify=y)\n",
    "\n",
    "cc = DecisionTreeClassifier(max_depth=7, random_state=13)\n",
    "cc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tr = cc.predict(X_train)\n",
    "y_pred_test = cc.predict(X_test)\n",
    "\n",
    "\n",
    "print('Train Acc : ', accuracy_score(y_train, y_pred_tr))\n",
    "print('Test Acc : ', accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test size 3. 비교 (max_depth=7)\n",
    "* 0.2 \n",
    "  - Train Acc :  0.7822014051522248\n",
    "  - Test Acc :  0.5327102803738317\n",
    "* 0.3\n",
    "  - Train Acc :  0.8123324396782842\n",
    "  - Test Acc :  0.5403726708074534"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=13),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15]})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pprint\n",
    "\n",
    "params={'max_depth' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}\n",
    "baseball=DecisionTreeClassifier(random_state=13)\n",
    "\n",
    "gridsearch=GridSearchCV(estimator=baseball, param_grid=params, cv=5)\n",
    "gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'mean_fit_time': array([0.00819745, 0.03659186, 0.01539392, 0.02219248, 0.03298721,\n",
      "       0.03978596, 0.0145936 , 0.01679544, 0.01870718, 0.01739302,\n",
      "       0.01779351, 0.01759257, 0.01419244, 0.01279564, 0.01339531]),\n",
      "    'mean_score_time': array([0.00419827, 0.01019416, 0.01159697, 0.01219754, 0.01859651,\n",
      "       0.00559888, 0.0095973 , 0.00859771, 0.01039877, 0.01119699,\n",
      "       0.00559878, 0.00639968, 0.00679874, 0.00339971, 0.00639701]),\n",
      "    'mean_test_score': array([0.35009698, 0.38950802, 0.43627226, 0.45688591, 0.43815905,\n",
      "       0.46247575, 0.48310704, 0.4586669 , 0.45127843, 0.4661788 ,\n",
      "       0.43995768, 0.46247575, 0.45501675, 0.45681538, 0.45681538]),\n",
      "    'param_max_depth': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      "    'params': [   {'max_depth': 1},\n",
      "                  {'max_depth': 2},\n",
      "                  {'max_depth': 3},\n",
      "                  {'max_depth': 4},\n",
      "                  {'max_depth': 5},\n",
      "                  {'max_depth': 6},\n",
      "                  {'max_depth': 7},\n",
      "                  {'max_depth': 8},\n",
      "                  {'max_depth': 9},\n",
      "                  {'max_depth': 10},\n",
      "                  {'max_depth': 11},\n",
      "                  {'max_depth': 12},\n",
      "                  {'max_depth': 13},\n",
      "                  {'max_depth': 14},\n",
      "                  {'max_depth': 15}],\n",
      "    'rank_test_score': array([15, 14, 13,  6, 12,  4,  1,  5, 10,  2, 11,  3,  9,  7,  7]),\n",
      "    'split0_test_score': array([0.30841121, 0.40186916, 0.40186916, 0.40186916, 0.40186916,\n",
      "       0.43925234, 0.42056075, 0.43925234, 0.40186916, 0.42990654,\n",
      "       0.39252336, 0.43925234, 0.38317757, 0.42056075, 0.42056075]),\n",
      "    'split1_test_score': array([0.38317757, 0.38317757, 0.46728972, 0.43925234, 0.41121495,\n",
      "       0.46728972, 0.54205607, 0.51401869, 0.47663551, 0.5046729 ,\n",
      "       0.51401869, 0.4953271 , 0.5046729 , 0.51401869, 0.51401869]),\n",
      "    'split2_test_score': array([0.36448598, 0.37383178, 0.42056075, 0.5046729 , 0.48598131,\n",
      "       0.52336449, 0.55140187, 0.5046729 , 0.45794393, 0.53271028,\n",
      "       0.45794393, 0.4953271 , 0.4953271 , 0.4953271 , 0.4953271 ]),\n",
      "    'split3_test_score': array([0.39252336, 0.40186916, 0.48598131, 0.5046729 , 0.47663551,\n",
      "       0.45794393, 0.43925234, 0.44859813, 0.48598131, 0.45794393,\n",
      "       0.45794393, 0.45794393, 0.45794393, 0.45794393, 0.45794393]),\n",
      "    'split4_test_score': array([0.30188679, 0.38679245, 0.40566038, 0.43396226, 0.41509434,\n",
      "       0.4245283 , 0.46226415, 0.38679245, 0.43396226, 0.40566038,\n",
      "       0.37735849, 0.4245283 , 0.43396226, 0.39622642, 0.39622642]),\n",
      "    'std_fit_time': array([0.00239906, 0.02990396, 0.00902111, 0.02495855, 0.04304518,\n",
      "       0.0355383 , 0.00343804, 0.00563468, 0.00825229, 0.00436308,\n",
      "       0.00534369, 0.00349828, 0.00396952, 0.00318621, 0.00205975]),\n",
      "    'std_score_time': array([0.00039795, 0.00729978, 0.01471316, 0.01449224, 0.02477525,\n",
      "       0.00101894, 0.00449714, 0.00531223, 0.00454387, 0.00610937,\n",
      "       0.00135697, 0.00119995, 0.00278457, 0.00049019, 0.00286956]),\n",
      "    'std_test_score': array([0.03785047, 0.01094339, 0.03406049, 0.04106208, 0.03561552,\n",
      "       0.03385406, 0.05368216, 0.04652873, 0.03043953, 0.04680642,\n",
      "       0.04959983, 0.0288385 , 0.04405312, 0.04414083, 0.04414083])}\n"
     ]
    }
   ],
   "source": [
    "pp=pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(gridsearch.cv_results_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, random_state=13)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* best_estimator: max_depth=7로 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기 성능 return 하는 함수\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score)\n",
    "\n",
    "def get_clf_eval_m(y_test, pred):\n",
    "    acc=accuracy_score(y_test, pred)\n",
    "    pre=precision_score(y_test, pred, average='micro')\n",
    "    re=recall_score(y_test, pred, average='micro')\n",
    "    f1=f1_score(y_test, pred, average='micro')\n",
    "    pred_proba=cc.predict_proba(X_test)\n",
    "    auc=roc_auc_score(y_test, pred_proba, multi_class='ovr')\n",
    "    \n",
    "    return acc, pre, re, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기 성능 return 하는 함수\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score)\n",
    "\n",
    "def get_clf_eval_w(y_test, pred):\n",
    "    acc=accuracy_score(y_test, pred)\n",
    "    pre=precision_score(y_test, pred, average='weighted')\n",
    "    re=recall_score(y_test, pred, average='weighted')\n",
    "    f1=f1_score(y_test, pred, average='weighted')\n",
    "    pred_proba=cc.predict_proba(X_test)\n",
    "    auc=roc_auc_score(y_test, pred_proba, multi_class='ovr')\n",
    "    \n",
    "    return acc, pre, re, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_clf_eval_m(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    acc, pre, re, f1, auc = get_clf_eval_m(y_test, pred)\n",
    "\n",
    "    print('=> confusion matrix')\n",
    "    print(confusion)\n",
    "    print('=========')\n",
    "\n",
    "    print('Accuracy: {0:.4f}, Precision: {1:.4f}'.format(acc,pre))\n",
    "    print('Recall: {0:.4f},  F1_1: {1:.4f}, AUC:{2:.4f}'.format(re, f1, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_clf_eval_w(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    acc, pre, re, f1, auc = get_clf_eval_w(y_test, pred)\n",
    "\n",
    "    print('=> confusion matrix')\n",
    "    print(confusion)\n",
    "    print('=========')\n",
    "\n",
    "    print('Accuracy: {0:.4f}, Precision: {1:.4f}'.format(acc,pre))\n",
    "    print('Recall: {0:.4f},  F1_1: {1:.4f}, AUC:{2:.4f}'.format(re, f1, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average=micro:\n",
      "=> confusion matrix\n",
      "[[19 11  4  1]\n",
      " [11 17  9  1]\n",
      " [ 7  5 34  4]\n",
      " [ 1  4 16 17]]\n",
      "=========\n",
      "Accuracy: 0.5404, Precision: 0.5404\n",
      "Recall: 0.5404,  F1_1: 0.5404, AUC:0.7234\n",
      "==========================================\n",
      "average=weighted:\n",
      "=> confusion matrix\n",
      "[[19 11  4  1]\n",
      " [11 17  9  1]\n",
      " [ 7  5 34  4]\n",
      " [ 1  4 16 17]]\n",
      "=========\n",
      "Accuracy: 0.5404, Precision: 0.5592\n",
      "Recall: 0.5404,  F1_1: 0.5386, AUC:0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('average=micro:'), print_clf_eval_m(y_test, y_pred_test),\n",
    "print('=========================================='),\n",
    "print('average=weighted:'), print_clf_eval_w(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 등급별로 얼마나 있는지 비율 확인\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "bb['grade'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Pie plot - Grade')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('grade', data=bb, ax=ax[1])\n",
    "ax[1].set_title('Count plot - Grade')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.54      0.52        35\n",
      "           2       0.46      0.45      0.45        38\n",
      "           3       0.54      0.68      0.60        50\n",
      "           4       0.74      0.45      0.56        38\n",
      "\n",
      "    accuracy                           0.54       161\n",
      "   macro avg       0.56      0.53      0.53       161\n",
      "weighted avg       0.56      0.54      0.54       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21739130434782608\n",
      "0.2360248447204969\n",
      "0.3105590062111801\n",
      "0.2360248447204969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21.9 : 23.2 : 31.1 : 23.8\n",
    "print(35/161), print(38/161), print(50/161), print(38/161)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 비교: 실제 비율(21.9 : 23.2 : 31.1 : 23.8) 과 유사함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022년 6월 13일 기준 data와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>POV</th>\n",
       "      <th>이름</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.249</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.661</td>\n",
       "      <td>ssg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.246</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.600</td>\n",
       "      <td>키움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.264</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.567</td>\n",
       "      <td>lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.269</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.542</td>\n",
       "      <td>기아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.256</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.483</td>\n",
       "      <td>두산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.260</td>\n",
       "      <td>3.86</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.483</td>\n",
       "      <td>삼성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.247</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.475</td>\n",
       "      <td>kt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.254</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.448</td>\n",
       "      <td>롯데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.248</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.383</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.242</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.361</td>\n",
       "      <td>한화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team    OBP    SLG     BA   ERA  WHIP    POV   이름\n",
       "3     6  0.330  0.370  0.249  3.56  1.21  0.661  ssg\n",
       "2     5  0.326  0.365  0.246  3.49  1.26  0.600   키움\n",
       "1     4  0.340  0.392  0.264  3.78  1.36  0.567   lg\n",
       "0     9  0.350  0.409  0.269  4.03  1.34  0.542   기아\n",
       "4     2  0.331  0.357  0.256  4.12  1.42  0.483   두산\n",
       "7     3  0.321  0.365  0.260  3.86  1.39  0.483   삼성\n",
       "5     1  0.326  0.352  0.247  3.58  1.24  0.475   kt\n",
       "9     8  0.313  0.366  0.254  4.03  1.36  0.448   롯데\n",
       "6     7  0.320  0.363  0.248  3.85  1.36  0.383   nc\n",
       "8    10  0.317  0.355  0.242  5.30  1.53  0.361   한화"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month6=pd.read_csv('2022yearcumul01.csv')\n",
    "month6.sort_values(by=['POV'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssg=np.array([[6, 0.330,\t0.370,\t0.249,\t3.56,\t1.21]])\n",
    "kium=np.array([[6, 0.326,\t0.365,\t0.246,\t3.49,\t1.26]])\n",
    "lg=np.array([[6, 0.340,\t0.392,\t0.264,\t3.78,\t1.36]]) \n",
    "kia=np.array([[6, 0.350,\t0.409,\t0.269,\t4.03,\t1.34]]) \n",
    "dusan=np.array([[6, 0.331,\t0.357,\t0.256,\t4.12,\t1.42]])\n",
    "samsung=np.array([[6, 0.321,\t0.365,\t0.260,\t3.86,\t1.39]])\n",
    "kt=np.array([[6, 0.326,\t0.352,\t0.247,\t3.58,\t1.24]])\n",
    "lotte=np.array([[6, 0.313,\t0.366,\t0.254,\t4.03,\t1.36]])\n",
    "nc=np.array([[6, 0.320,\t0.363,\t0.248,\t3.85,\t1.36]])\n",
    "hanhwa=np.array([[6, 0.317,\t0.355,\t0.242,\t5.30,\t1.53]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ssg :  [3]\n",
      "2. kium : [3]\n",
      "3. lg :  [3]\n",
      "4. kia :  [3]\n",
      "5. dusan :  [3]\n",
      "6. samsung :  [3]\n",
      "7. kt : [3]\n",
      "8. lotte:  [2]\n",
      "9. nc : [3]\n",
      "10. hanhwa : [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('1. ssg : ', cc.predict(ssg)),\n",
    "print('2. kium :', cc.predict(kium)),\n",
    "print('3. lg : ', cc.predict(lg)),\n",
    "print('4. kia : ', cc.predict(kia)), \n",
    "print('5. dusan : ', cc.predict(dusan)),\n",
    "print('6. samsung : ', cc.predict(samsung)), \n",
    "print('7. kt :', cc.predict(kt)), \n",
    "print('8. lotte: ', cc.predict(lotte)), \n",
    "print('9. nc :', cc.predict(nc)), \n",
    "print('10. hanhwa :', cc.predict(hanhwa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 0.5       , 0.        ],\n",
       "       [0.8       , 0.        , 0.2       , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.8       , 0.        , 0.2       , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.66666667, 0.33333333],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.11111111, 0.88888889, 0.        , 0.        ],\n",
       "       [0.        , 0.90909091, 0.        , 0.09090909],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.33333333, 0.66666667, 0.        ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.91666667, 0.08333333, 0.        ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.91666667, 0.08333333, 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [0.8       , 0.        , 0.2       , 0.        ],\n",
       "       [0.        , 0.90909091, 0.        , 0.09090909],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.8       , 0.        , 0.2       , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.8       , 0.        , 0.2       , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.90909091, 0.        , 0.09090909],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.        , 0.91666667, 0.08333333, 0.        ],\n",
       "       [0.        , 0.33333333, 0.66666667, 0.        ],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [0.        , 0.05263158, 0.47368421, 0.47368421],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.5       , 0.5       ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.        , 0.05263158, 0.47368421, 0.47368421],\n",
       "       [0.        , 0.05263158, 0.47368421, 0.47368421],\n",
       "       [0.        , 0.        , 0.66666667, 0.33333333],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.5       , 0.5       ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [0.33333333, 0.66666667, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.33333333, 0.66666667, 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.91666667, 0.08333333, 0.        ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [0.        , 0.05263158, 0.47368421, 0.47368421],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.05263158, 0.47368421, 0.47368421],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.8       , 0.        , 0.2       , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.        , 0.91666667, 0.08333333, 0.        ],\n",
       "       [0.        , 0.        , 0.66666667, 0.33333333],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.66666667, 0.        , 0.33333333, 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [0.        , 0.91666667, 0.08333333, 0.        ],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.66666667, 0.        , 0.33333333, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.33333333, 0.66666667, 0.        , 0.        ],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.66666667, 0.        , 0.33333333, 0.        ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.08333333, 0.91666667],\n",
       "       [0.25      , 0.75      , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.91666667, 0.08333333, 0.        ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.25      , 0.75      , 0.        , 0.        ],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.61111111, 0.38888889],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.4       , 0.4       , 0.2       , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.5       , 0.        , 0.5       , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.25      , 0.75      , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ],\n",
       "       [0.5       , 0.        , 0.5       , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.76923077, 0.07692308, 0.15384615],\n",
       "       [0.11111111, 0.88888889, 0.        , 0.        ],\n",
       "       [0.04      , 0.24      , 0.6       , 0.12      ],\n",
       "       [0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.0625    , 0.        , 0.875     , 0.0625    ],\n",
       "       [0.        , 0.        , 0.66666667, 0.33333333],\n",
       "       [0.08      , 0.28      , 0.6       , 0.04      ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ssg :  [[0.08 0.28 0.6  0.04]]\n",
      "2. kium : [[0.08 0.28 0.6  0.04]]\n",
      "3. lg :  [[0.0625 0.     0.875  0.0625]]\n",
      "4. kia :  [[0.         0.         0.61111111 0.38888889]]\n",
      "5. dusan :  [[0.08 0.28 0.6  0.04]]\n",
      "6. samsung :  [[0.08 0.28 0.6  0.04]]\n",
      "7. kt : [[0.08 0.28 0.6  0.04]]\n",
      "8. lotte:  [[0.25 0.75 0.   0.  ]]\n",
      "9. nc : [[0.08 0.28 0.6  0.04]]\n",
      "10. hanhwa : [[1. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('1. ssg : ', cc.predict_proba(ssg)),\n",
    "print('2. kium :', cc.predict_proba(kium)),\n",
    "print('3. lg : ', cc.predict_proba(lg)),\n",
    "print('4. kia : ', cc.predict_proba(kia)), \n",
    "print('5. dusan : ', cc.predict_proba(dusan)),\n",
    "print('6. samsung : ', cc.predict_proba(samsung)), \n",
    "print('7. kt :', cc.predict_proba(kt)), \n",
    "print('8. lotte: ', cc.predict_proba(lotte)), \n",
    "print('9. nc :', cc.predict_proba(nc)), \n",
    "print('10. hanhwa :', cc.predict_proba(hanhwa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 model 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델+data 있으면 성능 출력하는 함수\n",
    "def get_result_m(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    return get_clf_eval_m(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델+data 있으면 성능 출력하는 함수\n",
    "def get_result_w(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    return get_clf_eval_w(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다수의 모델의 성능 출력하는 함수\n",
    "def get_result_pd_m(models, model_names, X_train, y_train, X_test, y_test):\n",
    "    col_names=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    tmp=[]\n",
    "    \n",
    "    for model in models:\n",
    "        tmp.append(get_result_m(model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    return pd.DataFrame(tmp, columns=col_names, index=model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다수의 모델의 성능 출력하는 함수\n",
    "def get_result_pd_w(models, model_names, X_train, y_train, X_test, y_test):\n",
    "    col_names=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    tmp=[]\n",
    "    \n",
    "    for model in models:\n",
    "        tmp.append(get_result_w(model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    return pd.DataFrame(tmp, columns=col_names, index=model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lr_clf=LogisticRegression(random_state=13, solver='liblinear')\n",
    "dt_clf=DecisionTreeClassifier(random_state=13, max_depth=7)\n",
    "rf_clf=RandomForestClassifier(random_state=13, n_jobs=-1, n_estimators=100)\n",
    "lgbm_clf=LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time :  8.67140531539917\n",
      "              accuracy  precision    recall        f1   roc_auc\n",
      "LogisticReg   0.472050   0.472050  0.472050  0.472050  0.723394\n",
      "DecisionTree  0.540373   0.540373  0.540373  0.540373  0.723394\n",
      "RandomForest  0.552795   0.552795  0.552795  0.552795  0.723394\n",
      "LightGBM      0.503106   0.503106  0.503106  0.503106  0.723394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "models = [lr_clf, dt_clf, rf_clf, lgbm_clf]\n",
    "model_names=['LogisticReg', 'DecisionTree', 'RandomForest', 'LightGBM']\n",
    " \n",
    "start_time=time.time()\n",
    "results=get_result_pd_m(models, model_names, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Fit time : ', time.time() - start_time), print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ju-ye\\miniconda3\\envs\\ds_study\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time :  5.108438014984131\n",
      "              accuracy  precision    recall        f1   roc_auc\n",
      "LogisticReg   0.472050   0.369248  0.472050  0.412458  0.723394\n",
      "DecisionTree  0.540373   0.559196  0.540373  0.538600  0.723394\n",
      "RandomForest  0.552795   0.559112  0.552795  0.552633  0.723394\n",
      "LightGBM      0.503106   0.502774  0.503106  0.501447  0.723394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "models = [lr_clf, dt_clf, rf_clf, lgbm_clf]\n",
    "model_names=['LogisticReg', 'DecisionTree', 'RandomForest', 'LightGBM']\n",
    " \n",
    "start_time=time.time()\n",
    "results=get_result_pd_w(models, model_names, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Fit time : ', time.time() - start_time), print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ds_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8732d8724e13a34446af07cd964963f11c6ba042254b07431e7eaab0db3f24cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
